{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset \n",
    "we're going to use google's [WIDER FACE](http://shuoyang1213.me/WIDERFACE/index.html) dataset\n",
    "\n",
    "### required data\n",
    "* WIDER Face Training Images [[Google Drive](https://drive.google.com/file/d/15hGDLhsx8bLgLcIRD5DhYt5iBxnjNF1M/view)]\n",
    "* WIDER Face Validation Images [[Google Drive](https://drive.google.com/file/d/1GUCogbp16PMGa39thoMMeWxp7Rp5oM8Q/view)]\n",
    "* WIDER Face Testing Images [[Google Drive](https://drive.google.com/file/d/1HIfDbVEWKmsYKJZm4lchTBDLW5N7dY5T/view)]\n",
    "* Face annotations [[WIDER FACE](http://shuoyang1213.me/WIDERFACE/index.html)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my data dir :<br>\n",
    "/Users/tori/desktop/workspace/aiffel_git/data/GD14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, time\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_PATH = '/Users/tori/desktop/workspace/aiffel_git/data/GD14'\n",
    "DATA_PATH = os.path.join(PROJECT_PATH, 'widerface')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'checkpoints')\n",
    "TRAIN_TFRECORD_PATH = os.path.join(PROJECT_PATH, 'dataset', 'train_mask.tfrecord')\n",
    "VALID_TFRECORD_PATH = os.path.join(PROJECT_PATH, 'dataset', 'val_mask.tfrecord')\n",
    "CHECKPOINT_PATH = os.path.join(PROJECT_PATH, 'checkpoints')\n",
    "\n",
    "DATASET_LEN = 12880\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_WIDTH = 320\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_LABELS = ['background', 'face']\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(づ｡◕‿‿◕｡)づ\n"
     ]
    }
   ],
   "source": [
    "# first we're going to check bounding box format\n",
    "def parse_box(data):\n",
    "    x0 = int(data[0])\n",
    "    y0 = int(data[1])\n",
    "    w = int(data[2])\n",
    "    h = int(data[3])\n",
    "    return x0, y0, w, h\n",
    "\n",
    "print('(づ｡◕‿‿◕｡)づ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(づ｡◕‿‿◕｡)づ\n"
     ]
    }
   ],
   "source": [
    "def parse_widerface(file):\n",
    "    infos = []\n",
    "    with open(file) as fp:\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            n_object = int(fp.readline())\n",
    "            boxes = []\n",
    "            for i in range(n_object):\n",
    "                box = fp.readline().split(' ')\n",
    "                x0, y0, w, h = parse_box(box)\n",
    "                if (w == 0) or (h == 0):\n",
    "                    continue\n",
    "                boxes.append([x0, y0, w, h])\n",
    "            if n_object == 0:\n",
    "                box = fp.readline().split(' ')\n",
    "                x0, y0, w, h = parse_box(box)\n",
    "                boxes.append([x0, y0, w, h])\n",
    "            infos.append((line.strip(), boxes))\n",
    "            line = fp.readline()\n",
    "    return infos\n",
    "\n",
    "print('(づ｡◕‿‿◕｡)づ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(づ｡◕‿‿◕｡)づ\n"
     ]
    }
   ],
   "source": [
    "def process_image(image_file):\n",
    "    image_string = tf.io.read_file(image_file)\n",
    "    try:\n",
    "        image_data = tf.image.decode_jpeg(image_string, channels=3)\n",
    "        return 0, image_string, image_data\n",
    "    except tf.errors.InvalidArgumentError:\n",
    "        return 1, image_string, None\n",
    "        \n",
    "print('(づ｡◕‿‿◕｡)づ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(づ｡◕‿‿◕｡)づ\n"
     ]
    }
   ],
   "source": [
    "def xywh_to_voc(file_name, boxes, image_data):\n",
    "    shape = image_data.shape\n",
    "    image_info = {}\n",
    "    image_info['filename'] = file_name\n",
    "    image_info['width'] = shape[1]\n",
    "    image_info['height'] = shape[0]\n",
    "    image_info['depth'] = 3\n",
    "\n",
    "    difficult = []\n",
    "    classes = []\n",
    "    xmin, ymin, xmax, ymax = [], [], [], []\n",
    "\n",
    "    for box in boxes:\n",
    "        classes.append(1)\n",
    "        difficult.append(0)\n",
    "        xmin.append(box[0])\n",
    "        ymin.append(box[1])\n",
    "        xmax.append(box[0] + box[2])\n",
    "        ymax.append(box[1] + box[3])\n",
    "    image_info['class'] = classes\n",
    "    image_info['xmin'] = xmin\n",
    "    image_info['ymin'] = ymin\n",
    "    image_info['xmax'] = xmax\n",
    "    image_info['ymax'] = ymax\n",
    "    image_info['difficult'] = difficult\n",
    "\n",
    "    return image_info\n",
    "\n",
    "print('(づ｡◕‿‿◕｡)づ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "{'filename': '/Users/tori/desktop/workspace/aiffel_git/data/GD14/widerface/WIDER_train/images/0--Parade/0_Parade_marchingband_1_849.jpg', 'width': 1024, 'height': 1385, 'depth': 3, 'class': [1], 'xmin': [449], 'ymin': [330], 'xmax': [571], 'ymax': [479], 'difficult': [0]}\n",
      "--------------------\n",
      "{'filename': '/Users/tori/desktop/workspace/aiffel_git/data/GD14/widerface/WIDER_train/images/0--Parade/0_Parade_Parade_0_904.jpg', 'width': 1024, 'height': 1432, 'depth': 3, 'class': [1], 'xmin': [361], 'ymin': [98], 'xmax': [624], 'ymax': [437], 'difficult': [0]}\n",
      "--------------------\n",
      "{'filename': '/Users/tori/desktop/workspace/aiffel_git/data/GD14/widerface/WIDER_train/images/0--Parade/0_Parade_marchingband_1_799.jpg', 'width': 1024, 'height': 768, 'depth': 3, 'class': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'xmin': [78, 78, 113, 134, 163, 201, 182, 245, 304, 328, 389, 406, 436, 522, 643, 653, 793, 535, 29, 3, 20], 'ymin': [221, 238, 212, 260, 250, 218, 266, 279, 265, 295, 281, 293, 290, 328, 320, 224, 337, 311, 220, 232, 215], 'xmax': [85, 92, 124, 149, 177, 211, 197, 263, 320, 344, 406, 427, 458, 543, 666, 670, 816, 551, 40, 14, 32], 'ymax': [229, 255, 227, 275, 267, 230, 283, 294, 282, 315, 300, 314, 307, 346, 342, 249, 367, 328, 235, 247, 231], 'difficult': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "--------------------\n",
      "{'filename': '/Users/tori/desktop/workspace/aiffel_git/data/GD14/widerface/WIDER_train/images/0--Parade/0_Parade_marchingband_1_117.jpg', 'width': 1024, 'height': 682, 'depth': 3, 'class': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'xmin': [69, 227, 296, 353, 885, 819, 727, 598, 740], 'ymin': [359, 382, 305, 280, 377, 391, 342, 246, 308], 'xmax': [119, 283, 340, 393, 948, 853, 764, 631, 785], 'ymax': [395, 425, 331, 316, 418, 434, 373, 275, 341], 'difficult': [0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "--------------------\n",
      "{'filename': '/Users/tori/desktop/workspace/aiffel_git/data/GD14/widerface/WIDER_train/images/0--Parade/0_Parade_marchingband_1_778.jpg', 'width': 1024, 'height': 852, 'depth': 3, 'class': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'xmin': [27, 63, 64, 88, 231, 263, 367, 198, 293, 412, 441, 475, 510, 576, 577, 595, 570, 645, 719, 791, 884, 898, 945, 922, 743, 841, 980, 1001, 488, 586, 669, 744, 803, 294, 203], 'ymin': [226, 95, 63, 13, 1, 122, 68, 98, 161, 36, 23, 40, 23, 30, 71, 94, 126, 171, 98, 154, 97, 48, 89, 38, 71, 18, 56, 107, 2, 1, 1, 2, 3, 2, 0], 'xmax': [60, 79, 81, 104, 244, 277, 382, 213, 345, 426, 458, 489, 524, 592, 593, 611, 583, 697, 730, 845, 900, 913, 960, 937, 754, 857, 993, 1015, 500, 601, 681, 762, 821, 305, 216], 'ymax': [262, 114, 81, 28, 14, 142, 91, 116, 220, 56, 36, 61, 40, 45, 92, 114, 142, 229, 113, 203, 118, 69, 109, 54, 89, 34, 76, 120, 20, 18, 16, 17, 20, 12, 14], 'difficult': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-04 17:09:49.183222: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-11-04 17:09:49.183454: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(DATA_PATH, 'wider_face_split', 'wider_face_train_bbx_gt.txt')\n",
    "for i, info in enumerate(parse_widerface(file_path)):\n",
    "    print('--------------------')\n",
    "    image_file = os.path.join(DATA_PATH, 'WIDER_train', 'images', info[0])\n",
    "    _, image_string, image_data = process_image(image_file)\n",
    "    boxes = xywh_to_voc(image_file, info[1], image_data)\n",
    "    print(boxes)\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate TFRecord\n",
    "\n",
    "def make_example(image_string, image_infos):\n",
    "    for info in image_infos:\n",
    "        filename = info['filename']\n",
    "        width = info['width']\n",
    "        height = info['height']\n",
    "        depth = info['depth']\n",
    "        classes = info['class']\n",
    "        xmin = info['xmin']\n",
    "        ymin = info['ymin']\n",
    "        xmax = info['xmax']\n",
    "        ymax = info['ymax']\n",
    "\n",
    "    if isinstance(image_string, type(tf.constant(0))):\n",
    "        encoded_image = [image_string.numpy()]\n",
    "    else:\n",
    "        encoded_image = [image_string]\n",
    "\n",
    "    base_name = [tf.compat.as_bytes(os.path.basename(filename))]\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'filename':tf.train.Feature(bytes_list=tf.train.BytesList(value=base_name)),\n",
    "        'height':tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'width':tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'classes':tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n",
    "        'x_mins':tf.train.Feature(float_list=tf.train.FloatList(value=xmin)),\n",
    "        'y_mins':tf.train.Feature(float_list=tf.train.FloatList(value=ymin)),\n",
    "        'x_maxes':tf.train.Feature(float_list=tf.train.FloatList(value=xmax)),\n",
    "        'y_maxes':tf.train.Feature(float_list=tf.train.FloatList(value=ymax)),\n",
    "        'image_raw':tf.train.Feature(bytes_list=tf.train.BytesList(value=encoded_image))\n",
    "    }))\n",
    "    \n",
    "    return example\n",
    "\n",
    "print('슝=3')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "624dfac656ab975afd3f95c512185bd7e848a31e8758a11dbba4881f7f69423a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
